{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c67ea8b",
   "metadata": {},
   "source": [
    "# ResNets\n",
    "\n",
    "This week we discussed ResNets which are convolutional neural networks but with a residual learning framework realized by creating residual blocks via shortcut connections. In this notebook, we'll be implementing a fully connected NN, a plain CNN and a residual network and comparing the results on the MNIST dataset.\n",
    "\n",
    "We'll start off by loading the data. We'll be working with the MNIST dataset, which provides 70,000 labeled 28x28 images of handwritten digits. Our goal is to construct a classifier that recognizes handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d311a0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "import torch.utils.data as data_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "# Load the dataset... This can take a while\n",
    "if(\"mnist\" not in globals()):  # Don't load the dataset twice...\n",
    "    mnist = fetch_openml('mnist_784', version=1)\n",
    "    # Convert DataFrame to 24x24 numpy arrays...\n",
    "    imgs = mnist.data.to_numpy().reshape(70000, 28, 28).astype(np.float32)\n",
    "    # Labels for the mnist data, 0-9 being the number...\n",
    "    labels = np.asarray(mnist.target).astype(int)\n",
    "    \n",
    "    imgs_train, imgs_test, labels_train, labels_test = train_test_split(\n",
    "        imgs, labels, test_size=0.2, random_state=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7549fc57",
   "metadata": {},
   "source": [
    "Let's plot one of the digits at random to see what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7269cb01",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx = np.random.randint(0, imgs.shape[0])\n",
    "single_digit = imgs[idx]\n",
    "single_label = labels[idx]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.set_title(f\"Digit: {single_label}\")\n",
    "ax.imshow(single_digit, cmap=\"Greys\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d142723",
   "metadata": {},
   "source": [
    "We'll attempt to use a GPU to run these models. We'll check if one is available and assign it to our device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fced8572",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\") # GPU\n",
    "else:\n",
    "    device = torch.device(\"cpu\") # CPU\n",
    "    \n",
    "print(f\"Running PyTorch Using: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eff670",
   "metadata": {},
   "source": [
    "Now we'll prepare our data for training and testing using Pytorch's DataLoader which will pass in samples in “minibatches” and reshuffle the data at every epoch to reduce model overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a0d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the batch size:\n",
    "batch_size = None\n",
    "\n",
    "# Set up data loaders, these will be used to train and test models...\n",
    "to_device = lambda a: torch.from_numpy(a).to(device)\n",
    "\n",
    "train_loader = data_utils.DataLoader(\n",
    "    data_utils.TensorDataset(to_device(imgs_train), to_device(labels_train)),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "test_loader = data_utils.DataLoader(\n",
    "    data_utils.TensorDataset(to_device(imgs_test), to_device(labels_test)),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650c144f",
   "metadata": {},
   "source": [
    "## Simple Model: Fully Connected NN\n",
    "\n",
    "Now that we have our data set-up, let's start to implement our first network: a fully connected neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1073fdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        img_w: int, \n",
    "        img_h: int, \n",
    "        hidden_layer_sizes: list, \n",
    "        class_size: int\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self._in_layer = nn.Linear(img_w * img_h, hidden_layer_sizes[0])\n",
    "        \n",
    "        layers = []\n",
    "        for hls1, hls2 in zip(hidden_layer_sizes[:-1], hidden_layer_sizes[1:]):\n",
    "            layers.extend([nn.Linear(hls1, hls2), nn.ReLU()])\n",
    "        \n",
    "        self._hidden_layers = nn.Sequential(*layers)\n",
    "        \n",
    "        self._out_layer = nn.Linear(hidden_layer_sizes[-1], class_size)\n",
    "        self._softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        x = x.reshape(-1, img_w * img_h)\n",
    "        \n",
    "        x = self._in_layer(x)\n",
    "        x = self._hidden_layers(x)\n",
    "        return self._softmax(self._out_layer(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e137b258",
   "metadata": {},
   "source": [
    "Let's define some variables to use with our simple network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa504256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set these!\n",
    "img_w = None  # Height of the images\n",
    "img_h = None  # Width of the images\n",
    "hidden_layer_sizes = [None, None, None]  # List of None\n",
    "class_size = None  # Size of output\n",
    "\n",
    "simple_net = SimpleNet(img_w, img_h, hidden_layer_sizes, class_size)\n",
    "simple_net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32840245",
   "metadata": {},
   "source": [
    "We also want some functions to see how our network performs. These are defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef081397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for training a model...\n",
    "def train_model(\n",
    "    model, \n",
    "    train_data, \n",
    "    test_data, \n",
    "    optimizer, \n",
    "    error_func, \n",
    "    n_epochs, \n",
    "    augment_method=None, \n",
    "    print_every=300\n",
    "):\n",
    "    for epoch_i in range(1, n_epochs + 1):\n",
    "        for i, (img, label) in enumerate(train_data, 1):\n",
    "            model.zero_grad()\n",
    "            # If an augmentation method is passed, use it before passing the image to the model.\n",
    "            predicted = model.forward(img if(augment_method is None) else augment_method(img))\n",
    "            loss = error_func(predicted, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if((i % print_every == 0) or (i == len(train_data))):\n",
    "                print(f\"Epoch: {epoch_i}/{n_epochs}, Iter: {i}/{len(train_data)}, Loss: {loss:.04f}\")\n",
    "                \n",
    "        # Run against the test set and train set at the end of each epoch to get accuracy...\n",
    "        acc1 = get_accuracy(model, train_data, augment_method)\n",
    "        print(f\"Epoch {epoch_i} Train Accuracy: {acc1 * 100:.02f}%\")\n",
    "        acc2 = get_accuracy(model, test_data, augment_method)\n",
    "        print(f\"Epoch {epoch_i} Test Accuracy: {acc2 * 100:.02f}%\\n\")\n",
    "    \n",
    "    return model\n",
    "        \n",
    "        \n",
    "def get_accuracy(model, data, im_mod = None):\n",
    "    run = 0\n",
    "    correct = 0\n",
    "\n",
    "    for img, label in data:\n",
    "        img = im_mod(img) if(im_mod is not None) else img   # Allows us to modify the images...\n",
    "        run += len(img)\n",
    "        result = model.forward(img).cpu().detach().numpy()\n",
    "        correct += np.sum(np.argmax(result, axis=1) == label.cpu().detach().numpy())\n",
    "\n",
    "    return correct / run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f80707",
   "metadata": {},
   "source": [
    "Let's set a number of epochs and a learning rate for the model and see how it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eb7686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set these!\n",
    "n_epochs = None\n",
    "lr = None\n",
    "\n",
    "# Set up everything...\n",
    "optimizer = optim.Adam(simple_net.parameters(), lr=lr)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbe99dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model...\n",
    "simple_net = train_model(simple_net, train_loader, test_loader, optimizer, loss_func, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a7e947",
   "metadata": {},
   "source": [
    "### Is this model robust to translations?\n",
    "\n",
    "Our initial results are pretty good! Let's see the accuracy when we \"shift\" the image data around a little bit..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f115506",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.RandomAffine((-10, 10), (0.2, 0.2), (0.8, 1.2), (-5, 5))\n",
    "\n",
    "def img_shift_and_warp(img: torch.tensor) -> torch.tensor:\n",
    "    if(len(img.shape) == 2):\n",
    "        img = img.reshape(1, *img.shape)   \n",
    "    img = img_transform(img)\n",
    "    return img\n",
    "    \n",
    "\n",
    "# Show what img_shift_and_warp does to our images...\n",
    "random_idx = np.random.randint(0, len(imgs))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "ax1.set_title(\"Original Image\")\n",
    "ax2.set_title(\"Shifted Image\")\n",
    "ax1.imshow(imgs[random_idx], cmap=\"Greys\")\n",
    "ax2.imshow(img_shift_and_warp(torch.from_numpy(imgs[random_idx]))[0], cmap=\"Greys\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac1c209",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f\"Normal Test Accuracy: {get_accuracy(simple_net, test_loader) * 100:.02f}%\")\n",
    "print(f\"Augmented Test Accuracy: {get_accuracy(simple_net, test_loader, img_shift_and_warp) * 100:.02f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e4aeef",
   "metadata": {},
   "source": [
    "Yikes! Shifting around the numbers destroys the accuracy of our simple fully connected network destroys its performance. Can we fix this through data augmentation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb6c642",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model...\n",
    "simple_net = train_model(simple_net, train_loader, test_loader, optimizer, loss_func, n_epochs, img_shift_and_warp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ded958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Normal Test Accuracy: {get_accuracy(simple_net, test_loader) * 100:.02f}%\")\n",
    "print(f\"Augmented Test Accuracy: {get_accuracy(simple_net, test_loader, img_shift_and_warp) * 100:.02f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579ff327",
   "metadata": {},
   "source": [
    "Even after training the network using augmented images, we can see that a fully connected network still performs worse on transformed images. Even more interesting, is that the network now performs more poorly on the original data.\n",
    "\n",
    "### Question\n",
    "\n",
    "__Why do you think the model performs more poorly on the original data when trained on augmented data?__"
   ]
  },
  {
   "attachments": {
    "residual_block.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAADcCAIAAAD1BS29AAA9p0lEQVR42uydCzyU2f/Hv5sZlxiiSGxG2YrItdImalRyq2S13RAV2qLtotp0+6Vt+1e6alslXTdqVaui1LrUoEWLShhhSxuJsM1Ygxn5v+YZl3GNcUl833k1M2fOc55zzvM8n/me77mRampqAEEQpDsZgFWAIAgKDYIgKDQIgiAoNAiCoNAgCIJCgyAIgkKDIAgKDYIgCAoNgiAoNAiCoNAgCIKg0CAEqamppaWlWA8ICg3SXRQXF082+nrbtq1YFcingoRV8MnhlmaGR6eJSkqRRcmcKk4Vp0xUeZKZnhIANzM6PO0/USkyAFRViarOoGmJdzz90tLSioqKwqIirGoEhaYft2vOOK31LRAMGe0dbqYHUJbs7OxRKBB+/tkLIymsMASbTkjH0XC7+WdK4nnPafUh44fL8V6kRtnxP6vb+4c+eJSSaogqg6BFgwiHuJS8OIC8+y/7c2mbgnmmTaDznIn028p315/gfW8fFrJ7jDjWE4JCg3SF4NgeuPYy1egEAwAK1proE4HTAlNQZRBsOiFdidL6q7fMBT5vDvefKIvVgqDQIF2LlNbOk3b1n84G3CzDOkFQaJCuhZt/b6nb1fqPhcEblh9PxGpBUGiQrqMsZe1kt+cAi4/fCjlUa9ck+SzYEfoK6wb5rPkCt1vpNSqTuWOGeWABmG+9ftxFD4Abd9Blqe99/pc7QlMdtYTs3M7OztYYq06lUqdPn95ihKrKqqysrDHqY8TFxAe0hISEhBSFIk2RlpaWplCkeK+17ykyMjIkEnYpIB8Bb5FPLzChB/fRC15fD67VlKLB0vxLM3xEQyRv65mJVgZK0z28bMd09ARVVVUAkJube+bMmTaiJSQmCFcAMTExaela3ZGukyPZQbJfDh+uUvdPSUlpwAA0n1FokE+GlIL06+u+9xUUFQGgsKBAR5TM/4JZzPufHw4A4WFhttPXCXECUVFRAJg6depPP+1tLQ7zPVOKIvWhjpoPjWCz2Uwmi1XGYjKZLN47FrP2LbOMCGQymXl5eRUVFa3eZySSkpISVYVapzwqKsOHDx+uQqVSpaRwGCI2nZDPH37TycZmXvBvwd16ourqamYdJaUl/7zi/Xv1KvfVq3/+4b15VV5e3vyoQYMGUalUDQ0NPT19fT09PT19GRkZvGpo0SBIy4iIiMgStBahuLj4FU91apWHp0C8z6+eEFy+fJkfbeTIkXp6PM0x4CmP/uDBg7FuUWgQpL0MJtDT02sSXlFRkfosNYVHckpySuqz1L///vvatdpu/uHDh/OMHX2e6hgYjFdQUMCaxKYT0n+bTl0Fh8NJS0vj605ycvLT1KdsNrv+W11dXQtzCwtLS8OJhuhgRqFBUGi6hurqagaDwdeduLi4pOSkevto1qxZlhZWZmZmbbTXEBQaBIWmw7x9+zY8PPz2ndt//HGPxWIBwIABA76e9LWFpaWlheW4cePwiqPQICg0XdnCiouLvX379u07tzMzM/mBw4cPt7ayXrZsua6uLl56FBoEhaYr+fvvv++E37l9+/b9+9H8AYqGEw1Xrvxu/vz5YmJieA98ctCXhvQFRo4cuXrV6rDQsMK3RWfPnDOcaJiQmOC8zImqqrJlyw8vXrzAKkKhQbqewsJC/g97i+Tl5fXVgktKStrb28fGxiUmPFq2bFl5ebnPQZ8x6qOtZ1uHhYV++PAB7w1sOiFdxrt372im06aaTDUxmTpkyJBZ5mZmZrN27txJp9MfPHigPmbMgQM+/aEe3r9/f+HihZMn/fhOHCqV6uLiutJtJQ4+RqFBuoatW732H9jfPFxMTCzrefawYcP6VW1ER0f94ud38+aN6urqwYMH79z5P1cXVxEREbxPUGiQzho1al+NbD69yMPd49Chw/2zTvLz848ePeJ73JfD4YwdO/bA/gNmZrPwVukB0EfTZxkyZIj7avfm5szGjZv6bZ0oKSnt27f/WWravHm26enpVtZW1rOtGQwG3i0oNIjwrFu3fuDAgYIhri6u/a3R1JyRI0f+duW3yMgoPT29u3fDdfV0vv9+TUlJCd4wKDRIFxg1/dycaYKJsUn8nwn+p07Ly8uf+OXEGPXRR48dra6uxprpDtBH08cR9NT0Z+9MG5SVlR04sP/Q4UMVFRUmJlMDLwUOHToUqwUtGkQYowbNmdaQkpLatcs77Vn61KnT6PQH4ycYxMbFYrWg0CAdg++pQe9M26ioqNwNv7vRc2NBQcGMGdMPH0HTD5tO3YmHh3vf+0ErLCyUlZUlk8l9qVBkMvnYMd9JhpO6NtmbN284L3NmMpnz5tme9j8tLS2NDwUKTRfD5XIlBuJO158Na79f2x1DnHNycr5dMP/p06ejRo367UqwlpYWVnUnwaU8G8GXXX19/YR43B+yVxMVFTnLfFY3/UyqqanFxsS5e6y+cOHCZKOvA06fmT9/PtZ5Z0AfDYK0gISERMDpM36/nPzw4YO9w5L6BYwRFBoE6WKWL18e8nsIiUSyd7C/c+c2VggKDYJ0CzNmzLxy+UpNTc38b+ffvx+NFYJCgyDdgrX17AvnL1ZVVdnMs/kz/k+sEBQaBOkWvv3221Mn/f/777/Zs61TUlKwQlBoEKRbcHJyOnz4yPv37y2tLDIyMrBCUGgQpFtwX+3+44973r17Zz3b6v3791ghKDR9Bi6rtJRVwf1YtIqoY26mNrsZFcKdpZOH9yM2b9q80m3lq1evvl+7BmsDhaaPwEoNkBsqL2cZwPpIRE5WSEDM7aT3HOHO08nD+xf79x8YM2bMpUuXrl+/hrWBQtMn4FS2M6IYMSOntblMFYxAHVGSW2CqcIcjgkhISJw7d15EROS7Vd8VFBRghaDQfPZQ9F3zX77Kv7aU0rl0SFCVDvCWhTXaNYw3GO/ltbWkpMTF1QVro313ININ5McEBtx/Z7bc1VCJP0Wz6OYxP4aY0XdupnzJ4OYnnAi4p2S23M5QCQByk8NvhNHT8ooHyqnR5n4zx1CNnw63KP36rxGUr+0XGyvxQ3Jibobdj3+Rx5YbOWK4gjRAJchNtp+jytcl4JYmXL14OSKtXOLLmbaOdsZUgIrkm9fDglcAwIvYoHNiSZWVcrOXz1Fq88qX5iZHhscmM9KK2QO/HKljZb9Qn1eQioTAU/deS8//zkm9Tvm4Rckn/MKkpzk68c7VWkG4yVcDwvKHOS4aHe13MvJ5+XTXnU51JfpM8driFX7nTnj4nVP+p1xdXPGe/wg1iABVVVUksshEwwmdTCfpKI1EFqEdTeJ/ZGecJZFFSGTtO3n1EeaSyCJz/Z7W1HAivecS3zb8zT0az4/GTDrKS2dfbTpJfvZNYvL+5l5i1zDPzhVp/tWWGy9rakr2NQunM5vkl3/43CSmYG4F/2iRhZy6aCL2lzJaKmkbBWH60RqFa3vHd7KGIyMjSGSRDRvWf8K7JTMzkyItJS1DycrKwmenbbDp1C2MmrIAAGICIoqIjy/jI4nXtLt/5fINnIiQUACwnzGKlRowa3cogMn5+FecKm525CEACPN0jSoieprIYgAgzbeKKpK9PYLqYpbFnvIgQncyLtoKLmzh7hud//ZVkKcJABw4Es4C2e/y3iTf3AkAxtuv5+a9ys56M6HNlhiHA2M1lp+PTMkvLi3JS9kxBQDox4KeAlCs1vDSuXz6Xmlt3NyrnnQAWGE1tu2CiNUt6rLQ53pCTOg+s+F94CqPHj36//5vX3l5+XervsN7Hi2aT2DR1HAyXBtMGOZZ+7pfcrdgdk1NTWGkNlmEpO2dV1ND9+ZZBGuDXzb8Vm/hhRyNL+Ed+dSPsAsIi4adZM9LZEtJrRVCJ8wZP2aDSSKy5UZ2nY0ST+NFtk9iE4fy0/FLaiW7jSyaJrAJq6ouD0+JPGjfeMlpsH209xV+pCC12aN5R3K66Er1BouGz+TJX/OMxBg6Pj5o0fS87+ureas1CRMmH7gvQ64AaJgYa0D6mRsvAYqSItIBjJeYKUFpejTPIji+WM3U1FRHR8fUVGeWD73lHiAOEM5c9gvCnMiNu897YQrGWLTITK3OjaxI0wAAFofDP5SgvV1YUJHPuHru2LqVbg42Ngs9Axq+EB/nzLOV0s6EPwWAJzcv8IyUzXPk21UQ671rTfueU3Dr1q0AsGfPHrzr0Rn8CSrWwHYJ/Ox1PPqvjSNKwgDct/vMzvCctTsonnFI8W4YACywGMuLWNum0Bw1Wln5P2Xec7tMm1UAqjISzbqghk/WgLAMX8OhvsZTNGNi0wBg4yZzgWYQISu17Si54SMAMoTpsS5NPqcwaQX//dgpJkCcqJ7JixzBhx52IqJoueKNbXQAE+eZ6gCsNgtSK3R9svvc0tJKT08vMjIiPiG+y9cVRaFBPoK87lQrgLCo4AAJniEyYYK+3lAa7KaHXDg7NCoNwGOqBgWAJUboxMH4hDX6H1lCtCI1bGsGAJgsW6ac9TzPaoHHt67ui4m+nvYi1p5IrBveKwhnyr0Tq0wpJOAyzklorxCwacx2aIB3xiW/E5U8vbR0nCBPpN1WQfr4QMCtXlvt5tvt2bPn1s1beOe3CDadug2KzrcLADKCvH1CATwMqSCrNc0YIMzH60wGjPWcpc4Tecqk6YsAYIPnqXzBhktObkULPlqimWRJW+Dsvnevz+6t7tPU5bjtzAzxpL/ILWxHVG4lcZ5xUyZTeDlk3Q4OaRxByWbVIoA0b89d6QAbV5oRCtOBgvQ95syZO27cuPDwO0nJSXjjo9D0MOJG8z1q366m8QwPWa0FlrUBSywM+G/U57pbAUDseqqojdfu3bu93ExFpagaao+aDa6jjNAzBoDbu2YZG00xnqivPYaqLC+hsy65tC33C9+WIMvw1CDdx9rGwYEs6pba7OkXOJxCnaTJ+5V2Xrj72DE3U9lvdoc2iTxu9pKxdV4hOyOl9hSksk9f6S+++MJry1YA+PHHH/G+bxn0h3dLrxOfQjqNP56lbvxMxiVXkkBnUG23TnbkWpp2o+EnWy7lcfidPGfrx+MUxh/lHxtMj6dHRt4J9nMlBqcQ39Z2G8U3dBsx/Rp1JDFvbKkf5OKawW6516n2cHaGd8OoHO0t+7Y09DrVxb/E70dbe0OwF6n1gjTPXt/pdeJTXV09TluLRBZ5/PgxPkfNQaHpTqGpqanhsNlsTpMATkt9vGxmSWFhSQmTyWmWAD8+f4zfPoEu6JI7rgISwGlyopYCmCUlJWxOaxnlNM8PPzfNUircR2gcvw++fQVplkbfEpqamppLly6RyCIrv3PD5wi7t3ve2y4uLk5qEkBqyQUvTpGVl5eVpVBIzRIQjH/p8JHwhNScHEZC+Lk1mwN4TZ0hA+sjNjuySQBFVlZWnNRaRknN88PPTZPvWKlhW2MBwMPKQLbdBWmWmz6Hra2tpKRkSEhIdXU13vjoo/lcGTt3jRVA+pVds4311DW0psxZcTkDjFdfOLRYvYdzknXnAi8/223VsNNSUGHFxS0tLd+9e0enP8DaaPo7hlXw2dzHVNOQqtJcRtar/H//q6oSlZSlqo1VU6L0fE5GfLP3mvp/mrSv8aI0we4bu+Dg4GvXrtFoplgbKDSfLxSquj5V/RNnQlbNcI4aXosWsLCwHDhw4O8hvx875jtgADYXsOmEIN2AhISEhYVlYWFhTGwM1gYKDYJ0F9/YfgMA16/hKp8oNAjSbVhaWoqLi/8e8ntNTQ3WBgoNgnQLkpKS5uYWb968+SvpL6yNetAZ3IgvvvgCAJKTk8miWDOfzfXqbRgbG4eE/P7XX39NGD8BrxEKTUvVQSK5ubrFxsX2pUJVVlZmZ2dTKBQVFZW+VC4JcYm5Nja9MGP6+voAkIQWjeBPArYk+zzZ2dkaY9VtbOYF/xaMtdED/Pfff7Jyg7S0tJKTcJfuWtBHgyBdjKSkpLq6enp6OpvNxtr4PISGW8HFi4R8dhgYGFRXVz9+8hiroieFpuLeQYuvVA+WdvjAspPTRn21/XopXqheSkVOckJCMgN3pmuCvr4Bv1cBq4JPh53B3LIiRlZm0b8fW5yRPGiM7jglKRIAN3rPvFX+jP3hgbIdzp7U8t9Ohpm4TSiBZz/biuPl6m2wnrhMMooBzdjiJ4YUrI5GFg36g4UWmrJ7Bz1W+d5vZ2wFjysPN0zMv7vPxZ+x+GScrbqsEPkTVzH77Xcv3XkbPI01jy8cgxesd0EmK/NeRuCm3U3Q1dEdMGBAUhKu7Nlxocm5zFMZBSt3T4sxoiAqWvZo1Q+neeLtsGulqSKnirjxROGf5JvevmE863GEDJSlbHM7DRO9Ns0Sfv9TKT3nI/N/WvuDU/T0P2nyeMmQz4CBAweOGjWKwWB8+PABZ1d2TGiGTv4hOHzPOPW6XZtfVfFf5zktpgkuTEIz09cyf081NFKXjztoQQfYvGWRVOcyae7hC8EeLvtDGQesceQP8lmgrPxlZmZmUVHR0KFDsTY6oLVSKmP01Bv2hs98GE682k2gNn32tWZZG6nLQ1niMV8GKLrb6El1Vg5VZvxIAwjeE56PnVDdQm7USQeHdVG5RcmBu21MTU1NHW7m1K5gXpoTc8zLjQg0dVjpdTUht9VUuDnH1rm5rTuZI7D4eW74MTcHt5NRuf2tSocNUwSAN2/e4N0FnVicnBXkpKpGVVXzvNXaSrB54dvUqKqrr2V3zTrfMT+qUVWdzzNw+dWOkpWVRSKL2M23ayMOf0Fiwb99xHrAL+94N9vwX8T+bFL9drnEDrl1S6Azk+aSmy5Czk+ZdjSpv1X7Dz9sJpFF7ty5jXdgTU2NsA2Riqx70bzXxTP0W0mCmxwRAaBoPqnRDmfc0szw6DRRSSmyKJlTxanilIkqTzLTUwLgZkaHp/0nKkUGgKoqUdUZNC3BbiZ5zamj4TQ9NKHMcYwU/j50uVdXrL7TyOT4zW3Dcp+JDpGA0gTnObsAYOzq09d3LFQmlYTuXbXIJ/Syq6ezVZRpc38ZGSi1r01Tlu5/Vao4bBhh0RTg3SX8XKfSp3HEvsrTrI1a8fJycxODCwCsVOUanSL1jNNa30ZVP9o73EwPoCzZ2dlDcH+z889eGAkqiuzIKYrwPDHxZYWjFnZ0dxv+STecxlEATAGAce54DABo/BRx2IlQFSW7n87+HS+/NZb+19+lpvKyWF1tNZ0UCaEpwKZTJ4Tm8a0w4vX+6/RETlVVXTCnijNI11hPlgTAZWYCwEQd1caioOF2889l8PzSpqU+td3k44fLER6gUXYAJwBA3d7fx0VXWY7S1G6RG6kBUBD2LM9HSw2Vplsw3h5NqEwt5UxiIF5GalhgIBBXWVSUeYmYcPow4QUYotC0bdEoAkAB+miEFxpu5rWLDP7bTd8uaPydPf2lnixAxcvUJF6Dp+nmIeJS8uIA8u6/7M+lbeKZPBDoPGci/bby3fUniMPDQnaPaVlGxLUmT4Po+8VMdv1G9kjXIq0gKWi2Pgrh71EZ5OIU1CQmUwxrq10WTT4KjdBCU5r8B9HhpL7u0LpRorxfOlEoibgQLW44a8kyO35TisutBAAD3dZaOeK2B669TDU6wdOrgrUm+kTgtMCU1lQG6REa7VxL7I0bmwaWpxknaMBu1N8nR1Vrt/enn9alkpISWjSdEZqK6PMHAUDBYdNqW1p9qJm1Y0s3bhszFZTWX731t9bs8LrPm8P9J7bDGB8sIYGXrWfuDWXqCIA0oICyErWd+k+0tV4UVkCtWxhKH0QG9c/qk5SUHDhwYGFRId5JQk2qzKf7EP6ZNU7t2NZHrM2x6VJaO0/a1X86G3CzrB3nL8ap9z3mZdCdzHu5smJLYHK9PcPKZ9y82tp4JjIhL2n7/cIreD9JuSdXyrtf6b8VKCYmVtXgwUSh6QhxZw/zJHriLuuPeGR5FnPS4+cVrcfg5t9b6na1/mNh8IblxxM/liTSc8gbuvhb8t4cd5oooWPq4OBgqkOSU9X6ZvHmnBbVXlxjiacmAMTstqaI6pCl1dzP9G+bkETicnGIqRBCU5Z4zJ8BAOu2zG57MIvUV+MMACCnuNVqLktZO9ntOcDi47dCDtXaNUk+C3aEvmqtyfY84T4AUCRwBl+PIesU8iZo+yLe2wz65StBMRkAoLnsx+3qFMG2UsOTZb7j+sEFmsT7NABYuP1CkM+ifvsjISIigkJTS9vj+dh5MRtnqapRPRls3sfkU05qVFW1+adYHx0JyMneSFVVo67mH9hsXDFju6GqGlV19alkfuxYHyJl4u98aovJFx7k5cQplY3DLLt+ZHBNDYfNZnNa/7KksDCvsLCE2TQOh8Nmc5oexywpzMvLK2HWXqq2Uu7TqI6gDh4ih3fgR0cGl120dbheAABXrRypId6j/28Pz6b40dtBqh2exElWcD0sKbeEO6ZhglRZ6MF99ILX14NrB9EUDeYPGSUNH9FwqLf1zEQrA6XpHl62AutClL2IYABMpKlit1T7fj/a2CGgpW9J4uKt3wwkcVl5cdmWWwctHEaRlacIxBYXF8emEzad2moAzdplX/s28aCNuVsSwKqzDxaqt+e+ER9vYQdQcDNecDadlII0T2UUFBUVFBUBQEe0th3ELOb9zw9XUITwsLB/G/eIFT2OeQ5gYq2P8w/aQ0ZGxqZNG+MexjVxRr558yYoKOh//9uJVYRC05N8fBeEzLsXLkUklpSDnMaUbxfYaMm3+9epKNpywrLn6hsehbt3egxpxWVnjW3RcISeZa2CC0W0i9lzZoeH3xEXFx8zesyTp08GDx4sKyubnZ0NABERkVNNpmIVdTfjtLWysrIq2JVYFd263Qr33nbjVRcLdoRnOKp3znjOD/1qsgdYHcQFPdtP4qNEI6PJzcOnTp0W8UcE1k8PoKev++zZM05Vtxs1Qs9V7htCA1Aaa6nn8Jy299nZheKdFSw4Qo9Bc0YIo6ZJIJozPcaEieMfP35cwa4UERHp1hOlHPx6frO5yrcdx0BZ4mStBW3NVe4dPppOIzvF95AdRG8JSBR+I4MKRuCqiwUGW0+gynSU7du3NzdnUGV6jA8fPvTMvr0abjf/TEk87zmtPkRwrjLw5yqHPniUkmr4qXyc3d+xxb7mqapGNb+bzRLm6JIEZ6JDvQR7CIXCera14JpV9x/cxzrpMUaN/kpahtKDJ2Rf85xUN0xk0q3cktrxKNRtjE89KKRntsQtvb5Rf1OM1+N4lw7qadnPquMO07zo/i5KaM102lOD3pkeZpiSIolE+ufV6x48Z/4hc/5c5XqmBaacnfipl/Toub23y0rLpGQ7bLdVlJWRpKRQZLrEU4PemR5GiiKpoqKSnpbRo2cte+beaK5ylov6p3+Aem4jCCFUhli/BlWmazw16J3pYbhcbmVlJYXS4xvrCTVXubvBp7gp9Bh6YmJiHyvUmDFjRo8e7XPQpy8Vikwm2y+xHzx4cO/MHpPJ5D31Uj0tNC3MVaZ+ecV9IgpNL+LDhw+zZpn1ydGcmZmZfa9Q7//9d8eOXjrKmcViAUBPWzQCc5W/rTpvs/5q7Vxl1Qfe1iooNL2F6upqvsqcO3sea6M3ExUdeeHCBb7V0LuFpgf7k8syd8ywDQcw33rd21oLYO/5F++WEntYB7pP/Uo11VFLCoWmF6Gvr79kyRKsh97MsGGKFy5c6M05ZJURQtMTTadOzFXuKXBXYATpnqe/55pOws9VRosGQT5vSkv/BQCZQYN64FwTXc5mu7QQrtVKOFo0CNJH4G8dpzhUEasChQZBugv+Riv8rf4RFBoE6R6heVvAs2iIbeQQFBoE6Z6m0xu+0KBFg0LzGcBllZayKj46gLAi6pibqc1uRoVwZ+nk4UiLQpM/YMAABQUFrAoUmt4OKzVAbqi8nGUA6yMROVkhATG3k95zhDtPJw9HWuDVq1dKSkrdveQVCg3SFXDau9ysGDFEq7UtryoYgTqiJLfAVOEORzpKaWlpWVkZVYWKVcEHx9H0aij6rvkv7UBCjtLZy1yVDjCChTXac+YMAAxXGY5VgULTjeTHBAbcf2e23NVQib9WctHNY34MMaPv3Ez5ksHNTzgRcE/JbLmdoRIA5CaH3wijp+UVD5RTo839Zo6hGj8dblH69V8jKF/bLzZW4ofkxNwMux//Io8tN3LEcAVpgEqQm2w/R5WvS8AtTbh68XJEWrnElzNtHe2MqQAVyTevhwWvAIAXsUHnxJIqK+VmL5/T9kJipbnJkeGxyYy0YvbAL0fqWNkv1OcVpCIh8NS919Lzv3Oq36mSW5R8wi9MepqjE+9crRWEm3w1ICx/mOOi0dF+JyOfl0933elUV6I+yT//8IQGLZoGcL1FQaqqqkhkkYmGEzqZTtJRGoksQjuaVLvCYsZZYiVN7Tt59RHmksgic/2e1tRwIr3nCq62yQs/Gl+75WPSUV46+2rTSfKzbxKT9zf3EruGeXauSPOvttx4WVNTsq9ZOJ3ZdGtJ4vC5SUzB3Ar+0SILOXXRROwvZbRU0jYKwvSjNQrX9o7vZA1HRkaQyCIbNqzvnTfSocOHSGQRf39/fKb4oI+mWxg1ZQEAxAREFBEfX8ZHEq9pd//ib6dXFBESCgD2M0axUgNm7Q4FMDkf/4pTxc2OPAQAYZ6uUUVETxNZDACk+VZRRbK3R1BdzLLYUx5E6E7GxUZb0Lj7Rue/fRXkaQIAB46Es0D2u7w3yTd3AoDx9uu5ea+ys95MaLMlxuHAWI3l5yNT8otLS/JSdkwBAPqxoKcAFKs1vHQun75Xt9Z87lVPOgCssBrbdkH4PiAAWOhzPSEmdJ9ZH29TPH6cAgDaOtr4LKBF040WTQ0nw7XBhGGeta/7JXcLZtfU1BRGapNFSNreeTU1dG+eRbA2+GXDb/UWXsjR+BLekU/9CLuAsGjYSfa8RLbUrtPOpBPmjB+zwSQR2XIju85GiafxItsnEatSs/np+CW1kt1GFk3TBa8Jq6ouD0+JPGjfeMlpsH209xV+pCC12aN5R3bVJty93KIZp60lJi7KZuNG8e3aexsR2vf11bzVmmd+Trv7V765ZXHIFQANE2Ogx5y58dLPbnBSRDqA8RIzJSi9Fc2zCI4vVntywqS4uHjwYIiJTWu5B4gDhDOX/aIUZGUhN45YE6DReiyLFpmp1bmRFWkaEJPB4nAAxKG227rdOyZW5DNC792Li097V/CWxXzR8IX4OGdPk8s+9DPhT+e46T+5eYFnpGyeIw+l1z9eEOu9a037ww3HZrMzMzM1NDT67abj6AzuuYo1sF0CP3sdj/5r44iSMAD37T6zMzxn7Q6KZxxSvBsGAAssxvIi1rYpNEeNVlb+T5n33C7TZhWAqoxEsy6o4ZM1ICzD13Cor/EUTf5jvHGTuUAzqFZWCOSGjwDIEKbHujT5nMKkFfz3Y6eYAF8v6pi8yBF86GEnIoqWK97YRgcwcZ6pDsBqsyC1QtdPus+fpj798OGDrq4uPgYoNN2OvO5UK4CwqOAACZ4hMmGCvt5QGuymh1w4OzQqDcBjqgYFgCVG6MTB+IQ1+h/59atIDduaAQAmy5YpZz3Ps1rg8a2r+2LjjvRriLUnEuuG9wrCmXLvxCpTCgm4jHMS2isEbBqzHRrgnXHJ70QlTy8tHSfIE2m3VZD+NRAwJSUFAHR19boktYqi3KwCpvSXo6iyn7F9hM7gboOi8+0CgIwgb59QAA9DKshqTTMGCPPxOpMBYz1nEXtgUCZNXwQAGzxP5Qs2XHJyK1rw0RLNJEvaAmf3vXt9dm91n6Yu197FjYkn/UVuYTuiciuJ84ybMpnCyyHrdnBI4whKNqsWAaR5e+5KB9i40oxQmA4UpM/D9wTr6X1caHKiznl5eZ0LZ7QRJz3IWd9Ab47/k27Nc3tygkLTOxE3mu9R+3Y1jWd4yGotsKwNWGJhwH+jPtfdCgBi11NFbbx2797t5WYqKkXVUHvUbHAdZYSeMQDc3jXL2GiK8UR97TFUZXkJnXXJpW25X/i2BFmGpwbpPtY2Dg5kUbfUZk+/wOEU6iRNANjqvHD3sWNuprLf7A5tEnnc7CVj67xCdkZK7SlIZX+68ElJSTyLRuejTafSsHUrDvjsd7n0rA05Jovx2qEjxLuw3VmRn8PIyS3itpWT5nFQaHor1K9tjYk3G2eNJ9qoslO/Xc5/Pmfw2xu8MMPLGffcp2gChB7YvcvbJyAGwMrzgpoE36khVu/wLXqeEkMcGxQZFxV+71bgz8umAGT4el5Mrm8VcZppB//2FFebfc3TGgDCrgS16CsROJxkvuPKDkuAjFBvz/VnYjU3/ripaWwlo80L+AI6X7veRdRmQcT6TQuqoKDg8ePHurq6MjIyHzV6R1uZAIDx8J7dvIz1xF5DS33UgiRW6zlpIU7nwI63bunebujnZrPZnCYBnJb6eNnMksLCkhImk9MsAX58/hi/fQJd0CV3XBs6nomIzY5sEsAsKSlhc1rLKKd5fvi5aZZS4T5iAB6/D759BWmWRh/t3j579iyJLLJjx/auSvApMUqz7ip3yT3JH6Ng/5TTuTjYvd2bvO3i4qSmAS03tCiy4pSWExD8eOnwEW13m1FDyO+y4o9vDuD9GA0Z2HLCLQRQWvcnNo0tmJ8m37FSw7bGAoCHlYFsuwtC6iddvbfv3AYAC0vL9kTOjTr509lkTWevNaYNTv3cmKsnT/0an8cE6VGOG9ZpiA1s2uLKibkY8GtUfBYTQHn0pLnObnaGdYdzc09u3MYY4bp3lVroieO/hsQzQVqHZuO+1kmNd1EqYk4euJP7+ikvapC+8/A9o6FSwWKjm/HbhpwMbTGOh/l/u/b+DsozvbbbyTfkJf+c167IEs3/HVmjJo4WzSe0aLoO9svIuc0mE9DWXirs8Zwk7aMR0wjon7A2eqdFw+FwZOUGDVVUqK6ubt9UlbmCU1V49stZ1xZmmQhYNC/veDf/1v5sXQrMpLktHU4ibyGGWJYcbeGrfSWNctJynPy6iSlnMxpGIfKnyJDItHgmTkHoM75lqmlIVWn208So8Hu3bobejYxjvCyNOrxYvsdzMuKbvdeu3ru+9mu8KE2IjIxgsVizZs0aMKBdTxaZGBQg3WCrRNm7BhB9iz8lZL1KjTxt3NSYSXCeswsAxq4+zXhbxip+FUS43i67ekYV1frk6q1JK88LyRmZd335bsH9JyPyAWQXZWQmx1wgkjU5H5OSmpSSmuEs2ygnLccZpm62Q4MXdCH4UX12Hl0lcrtghQ4FfTR9xaJBer9FM892Hokscu/eXeH8LxmX+ObM3AYDoZBuL2DRZJy1r5/zUe+p4/vL9vH9ZbXzVETs/eIbzy8RsJtq/S9zk9ite4JaipNRa22tzeAIzrMR2RKZh5MqEaSHeP36dVhYqJqa2owZM4VLgcN6S1grKw3qDQR5462+i+ojlDOJTqCM1LDAwHMEgYEXL8Xywh4mCMwUAet1Sw3re5QMbBY1spu4nEZjH1qkpTjqVguIYQ2+N5NKedZV0r0z/CEOkz++4gc6gxGkawgIOP3hw4cVK1y++OILYdPgCcwIdWXBx1LgSS99FMIf0xTk4hTU5Ehmk2HfDZNRum4Uk/yEzQtg6RXYejlmk+GchMsBhCwu0W6Hmx+FBkG6AC6XG3AmQFRU1GmpU2fTquQ09uM0yBB1kibEpoHlacYJGrAbDaaTo6p1fykpM513wpVd8HNYqteI339OA4DlDobtEREUGgTpAs6cPfPmzZvFixcPGTJE6EQ4lbyWUVhAROka/bqBA0X3QuqNF5IydQRAGlBAWYna6dEClHZMcm0aR36yzULYdRkC7GfEpwMxxEFbFlBohCM5OdnJeWlfKlFmZqa8vLycnFyfKVFUVFTvyQyLxfrf/3aSSKTt23Z0Jp0RhqYAoZDhdeDqnJ/s1IGVe3LjnA23GyIo6k7mRbiyYouF9oHF+vynl5XPiH74cryNuVI7n+ba9Uae/p1Xoa8GpaUcWVlKe+OIj3P21Lzsk5aewTNnjH9cqNa+k6LQNK4OEklVVfXly5eXLl3C2uj9qFB7xaK8+/fvKyoqWuOx5quvvupMOrKGc3fAem+AA4u1DuzWhIy0pk4SQxd/Sy+X23DcaeLxfSYLtZXzngbFZACAZlSxuVI7l7CXkBnKe0lbpCG1GyDd8gIrZHF74vBtqMmO68Cndjb/im902vtk4c0qyBdffBH/Z8Lr16/7UqH++eefebY2NBrtwH6fvlQuCQmJ0aNH94bqPXL0yKBBg7Zu3dbpxKjb8+LYC4wOxAJfZay2X1im8OAbj4C6JT5knULeSO1ev2h3EGTQL2fwAzWX/bi9frn4liYnNQ4jqXmFHzpjvh4AeM0fRdGWhKHVOOLq/HVCADR+mqnW7gYcjsjo82RlZZHIInbz7bAquoOFixaQyCKHjxzumrlw/KEvJYV5eXklzNpBLC3E4bBLCgvzCgtLmE2/4rQwm47TWgolJfVT0toTh0/2ltrhyBk41wlBeoKAgICrV6+qq6uv+m6VcI31pnPh+D5YWXmKgI+1hSVBSeKy8uKyLTf/m6fY0lmIFDoYh/BOx1w7wHs1cbZSb385ccAeggjJ06dPv1+7RkJC4nLQFVFR0f5R6Io/TnmBwMqK6KNBkG6ExWItXLSgsrLytH+ApqZmvyk3B4aYjNWAVVusOrR7KgoNggjDyu/csrKyHB0dly5d2p/KTVl8OGpxxw/DphOCdBhPzw2//fabpqbmcd+fsTbQokGQrmfDhvXHfI+pqKj8fj1EQkICKwSFBkG6S2UiI6JUVVWxQlBoEKSLWb9+ne9xX1QZIUAfTd8kMzPz4Z8Pa2pqmn/FYrGuXbuKVdQhWCzW4iWLUGXQokEaMXLkSOvZVuXl5SYmJqpU3lORk5Pt5bWFTqf/lfTXoUOHsYraz9OnTxcuWpCVlaWlpRXy+w1q75hg9XnxRYs/ekgfwP+0/6pV3zUPHzp0aHZWDu4/304CAgK+X7umsrJy6dKlvseOo/cXm05IIxwdHJWVlZuHb9jgiSrTHv777z8n56Urv3MbMGBAwOkzp/0DUGVQaJCmiImJeXpubBI4ePBgVxdXrJyPEhwcrKOrfenSJXV19T8fxjs6OmKdoNAgLbN82XIFBQXBkLVr10lKSmLNtEFycjKNNm3xkkWvXr1asWJF/J8J/WmGAQoN0nEkJCTWr99Q/1FGRkbYScb9grdv37q4rpj0tWFsXOwUoykJ8Ym/nPBDXUahQT6Om6tb/QqeazzWSEtLY500h8lk7tu/T11jzLlz51RUVIICL0dH39fT08OaQaFB2oWUlNT3368FAElJSXd3D6yQJmRlZa1d+z1VVWXbtq01NTXe3rufpabZ2dlhzXQt2L3d93n//v1ItREr3Vbu2fMT1kY9ERF/HPP1vUPsyT9o0KDly5Z///3aYcOGYc2g0CAdoKSkJCQk5NFfiU+fPH3x8oWcnNzIkWrjDQxopqbGU4z7bbWUl5f/eunX48d9MzIyAEBdXd3d3cPB3mHgwIF4z6DQIB3gn3/+2eX9vytXrlRUVPBDSCRSdXV1/bUeN27cpo2bFy5c2H/qhMVi3b59+/rv18PD75SXlwOAubnFGg+PGTNmdmJjSaTd4OLSfYyAgABZuUEksoiS8rDt27dFR0e9f/++pqbmw4cPz58///XXX80tzImt2kVsv7EtKirq27VRUlJy/vz5uTZzB0pK8EutpDzs++/XZGZm4q3Sk6DQ9Cm2b99GIotISg30OehTWVnZWrTHjx8bjNcnkUW0dcYVFhb2vXp48+bNKf9T5hbm4hJifH1RHUFdt27tA/oDvmWH9DDYdOo7/LT3p507dwwbNuzO7fCPjjHjcDjLVywLCgrS0dGJjYnrA5MSnj9/HhcXFxsXExcXl5OTww8cOXKk7Tzbeba2E8ZPwCYS+mi6F24FlyTex+epxyfET51qIicnR38QM2rUqCbfMhiMYcOGycjICAZWV1cvWLjgxo0Qzw2ee/f+32dX5Orq6pTHKTxxiY19+DCusLCQH04mkw30DaZPnz5vnq2Ojg4+5Oij6RDsuz7malSfkg4fyDpuqKq27VpJ37VLP3z4oK0zjkQWuXEjpPm37969o0hLubuvbv5VcXGx8pdKomLktn0Wb9++ZTKZn7yYTCYzPiH+7NmzmzZtNJtlJjNImt8sIpFFZOUGWVpZ7vlpzwP6AzabjU2V3san+Z3nlhUxsjKL/uV8JB550BjdcUpSJABu9J55q/wZ+8MDZTt8Nqnlv50MM3GbUALPfrbtk9OW7927m56ebmFhOWfO3ObflpaWstnsgrdvm38lJye3c+f/Vq36zs/vlxYXqcnLy/PxOfDXX3/FxMT2cKH+/fff9AziX3paekZGRkZ6Xl6eYARFRUULCwsjoylTjKZoa2sPGICjT3svPS80ZfcOeqzyvd/O2AoeVx5umJh/d5+LP2PxyThbdVkhTimuYvbb71668zZ4GmseXzim713FgDNnAGDt998LceziRYt/+GHzxV8vHjx4SNCL8fLly/37952/cL6qqmrnzv91X+ZLSkry8vLy83n/8f7l5/3994v09LSCggLBaJKSkuMNxmuM1dDQGDtWQ0NLaxwuQIVC0yo5l3kqo2Dl7mkxRhRERcserfrhNAAYOOxaaarIqSLsGFH4J/mmt28YAOiPkIGylG1up2Gi16ZZSkKfV0rP+cj8n9b+4BQ9/U+afF+7ig8fxklJSU2bRhPiWElJSROTqaGhtzIzM9XV1QEgOzv7//bt/fXXX6urq/lxTExMhM5beXn5+/fvmUxmcUlxPl9K6iSFkJX8+sE+gkhLSxtONOTLiiZPWMYOHz4cvbkoNO1l6OQfgsP3jFNXqj3xqyr+6zynxTQ1gczQzPS1zN9TDY3U5eMOWtABNm9ZJNW5kpp7+EKwh8v+UMYBayGKnXnB2SqU9vg3R6ledgnfvHnz9u3bqVOnCbYdioqKuFxu3ftCAKioYL9586Y+wqBBg+qXcdLX1w8NvfXkyZMPHz7s/b+ffvvttw8fPgieQnaQbHp6elVVVRWnisPhcHjvqiorK5lMFpPF5OkIISXvme+ZxOfaQIJ6tWqOmJiYsrKyspKy8pe8/5V475WUlJWpKlQlJSV8OFFohEdKZYzglNjMh+HEq90EatOcaM2yJlpaicd8GaDobqPX2QecpDLjRxpsC94Tvs7cWqnDBedUFsArJqf3XcLS0lLCYTG0PuTI0SMbN3o2iRYeHq5CHS7o4HiWmsbvh+KvWXPA58CTJ49bPIW+gZ4QhpK0tPTQoUOlKdLSMjLS0tJycrI8FamXE2Xl+mnlCApN9/prUu7y2kcwfyq1lYzkx91KAjDfZNMVzR3x6ctXbIs+fT0ix9pROE+NGLn3XUK+IcPlNhgOkydPtrKyrqqqqm+8xMXFKigo6Ojo1sf5Sk2tfnYP3+iYMsVIQlw8PiG++SlsbOaJiYmSyWRRUVEyife/qKiomJiYFIUiIyMjTZEm/pOWkeYJigwhK+iaRXqN0FRk3YvmvS6eod9KPrjJEREAiuaTGrn9uKWZ4dFpopJSZFEyh2fNl4kqTzLTUwLgZkaHp/0nKsXTg6oqUdUZNC3BbiZ5zamj4TQ9NKHMcUx3t4CEzmRH4S8MnJ2dVR8yccLEkN9D6j9mZ2drjFWfPNko+LfgFlP4mxjeNnPGzCOHj0ZHR/24Zw+d/kAwgu8xX0VFRXxakM9SaEqfxtF5r9OsjVppkHNzE4MLAKxU5RrlM/WM01rfRl0So73DzfQAypKdnT0KBcLPP3thJKgosiOnKMLzxMSXFY5a3dzRLXwmOwiFQhk9evSzZ8/YbLZwq2enpKQAgJ6ePgDQaKY0mmncw7g9e/b88cc9foSYmJj58+fj04IIb3d/wnM/vkW0m+D+6/TEuNjYur/o6OiUUr4fk8vM5P1A66g2FgUNt5t/piSe95xWHzJ+ONHalxpVu2CRur1/6INHKamGTR9guZEaABD2LK+iu0vXiUx2mKkmU6urq69duybEsW/evIl7GDdixAhB/6vRZKPbYbcfPvzT2no27wrdj8ZHBfk8LRpu5rWLDP7bTd8uaPydPf2lnixAxcvUJF6Dh9Ikl+JS8uIA8u6/7M+lbeKZPBDoPGci/bby3fUniMPDQnaPadlgEdeaPA2i7xcz2QAdN2kGdcQhJHwmO4yrq5v/af/jx32XLFnS0T7g0wGnq6urly1b3vyrCeMn/H799ydPnvzid4LFYlEoFHxgkM9MaEqT/yA6nNTXHVo3SrSqCkAUSiIuRIsbzlqyzI7/28rlVgKAgW5rrRxx2wPXXqYaneDpVcFaE30icFpgSuceYG5Zfn4JkBrVDFmCXMQEYDx5WVQkx2na9SQtpyTV6hm7J5ON0dXVNTWdHhUVeeKXE6tXrW7y7ZAhQwYOHDi62QQoAHjx4sWBA/slJSWdnZxbS1xHR8fvl5P4qCCfo9BURJ8/CAAKDptW2zYMMzOzbmn3nMo2+pSV1l+99bfW7PC6z5vD/Se2Y/Dw4NZ9GWWpJ03mHW/lS4bNhLDmoQoe1x9u0OvyTHaIX078oqevu2XLD7q6ukaTjRrZYYMGZT3PbjKjkt8btXSpI5vNPnz4yNChQ/FhQPqc0OTTfYgHdo3T1x+P3HafspTWzpN24W61u9afDbi56IDtR50exexWm05SGo5hodZNKoY0EKI8zfe9WhF4aaEMhyv4FYfLkVNV/8j5hMpkhxg5cuRx35+XLXe2tra6dvWaqen0RlLYeHcn/kLC87+d/2f8nzNnmuEeLEi380mmcsb+aK5GVVWbf57V9rTr1PO8aKuutTEbl5N314Kqqibw961vQhtppp53UqOqHk/u8Fxuxvn5aoanWEKVt6OZFBp/f3/+bOZ169YWFxe3Fu3OnduqI6gksoipKa28vBznFiPdzafodSpLPObPAIB1W2a3/asu9dU4AwDIKea2mlTK2sluzwEWH78Vcqi2MyfJZ8GO0FetNdmeJ9wHAIpEh0fecSpZwpa3o5kUnhUrVoSFhikrK/se96Wqqri4rggKCsrMzCwuLn779i09hu5z0EdPX3f2nNmvX79evWp1aGgY7ieN9BGLhp0Xs3GWqhrVk0FYJsmnnAhzph3WASd7I+/3fzWjRZOGxdhuyLMOVp9K5seO9XGqNxnOp7aYfOFBXk6cUju+YknqKXNhLBphMtlZ/v333+3btw1TUqxfrqXJn7mF+f370fgzi/Sl9WjKLto6XC8AgKtWjtQQ79H/t4dnU/zo7fBxJwVJeZIVXA9Lyi3hjmmYnVQWenAfveD19eDatSaKBvN3XyQNH9FwqLf1zEQrA6XpHl62ArMNyl5EMAAm0lS7fVmaTmSy08jIyHh77962bXtkZMSjR4/iHj6MioqUl5efPXu2gcH4aVOnjR49Gn9ikZ6kB5pOUrN22de+TTxoY+6WBLDq7IOF6u151sXHW9gBFNyMzxVMUEGa9wArKCoqEOPidURr20HMYsLxSYQrKEJ4WNi/jZ26RY9jngOYWOt3/wxs4TPZVYiKilpYWO7YsfPn4z8DgJHRlJN+p1xdXFFlkJ6nh9YMzrx74VJEYkk5yGlM+XaBjZZ8uy2KomjLCcueq294FO7e6R7hisvOGtui4Qg9y1qlw8/2M38LmwDbx/EuUp/bNebPdbKxmdfaXKfOVGlO8pN3IDNWXx0H8yFtNU565jRjZjl6z3IU5kh547UOiqsuHrzFWOGo3rkGT37EtmgAq4MzVIQt9SC8YRrDeuIyySgGNGOLnxii0iCftOnUWSk0W39gNID3vpDOTU/i3vtlD4Dikc1zhJMrLZc72eGfnznTvZDJyryXEWSsCuQzFxoA2Sm+h+wgektAYqnwJj4jcNXFAoOtJ6xVSHjVEQSFpgXUbHfvnw+Hv118L6dMmONLE1eZ74SJXn4uenjJEQSFpjXEbQ8k75/PWLUkqONKU/az3gI6zYse6CKLF7wVcqNOOjisi8otSg7cbWNqamrqcDOntqlamhNzzMuNCDR1WOl1NSG39eZpzrF1bm7rTuYItHJzw4+5ObidjMrFSu7XfF7DflglwoxwY7NYnH48ViorK4tEFrGbb9dGnKSjc5sM6tsXX1JTU/Pyjnfz8X72Z5PqajbJnhcyN4m/uxwzaS7xMZ7ZNGXa0SQctIZTED4bpGSF8caKS0mhY6ZtyGL1nUYmx2/eu+Z7SHuIBJQmOM/ZBQBjV59mvC1jFb8K8rQGgMuunlFFLaYClNrXpilLYxX3b/AB7JtUV1eLiIgI8a1/0g2ncRQAUwBgnDseAwAaP0UcdiIWh1ey++ns3/HyW2Ppf/1daiqPLVEEhaZ/k5WV9eOe3XPn2Aju/cblclMepzx48KDgzRsfn4PNjzLeHk2oTC3lTGIeaUZqWGAgEHsqiIoyLxFb4z5MeAGGKDQICk3/Rl1dvbKyavGSRQDAX9Tq3r278gpDysrKACAu7mGLR0krSAp8Kn0UEkq8CXJxCmoSkymGdYyg0CAAW37YEhLyOwC8Jbb3Ly8v54fPmDFz4oSJLR9TKfiBQp2kCbFpYHmacYIG7EZrdchR1dqZDTJKEoJC04fR19e3sLC8c+d2k3AvL6923hvK1BEAaUABZSVqO4dTE22tF4UVUOsWhtIHkUF4LRDcTrAv01xTTIxNjKcYt/NwRd3JvJcrK7YEJtfbM6x8xs2r4fktr0VGJuQlbb9feAUAVOSeXCnvfgWvA4JC06eZZDipyeLB7TZneMgbuvhb8t4cd5oooWPq4OBgqkOSU9X6ZvHmHHZLB4hrLPHUBICY3dYUUR2ytJr7GbwICApNPzNqDCcaNtGdjyHrFPImaPsi3tsM+uUrQTEZAKC57Mft9atCNF7flGS+4/rBBZrE+zQAWLj9QpAPcTh6avo3PbQeDfIJodGmxcbFAsCNkBuWllZYIQhaNEh3GTW6uroWFpZYG8gnAXud+j4zZsycMH7Cxo0bO7pbLoJg0wnpACkpKTo6OgMGoAGLoNAgCNJHwZ84BEFQaBAEQaFBEARBoUEQBIUGQRAUGgRBEBQaBEFQaBAEQVBoEATpAf4/AAD///DOET5NkBs4AAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "id": "a79b1b2e",
   "metadata": {},
   "source": [
    "# Using a ResNet\n",
    "\n",
    "Now that we've looked at a fully connected network and a, let's see if we can achieve even better results with a residual network (ResNet).\n",
    "\n",
    "We'll start by defining a residual block. Let's do a quick recap on what this is.\n",
    "\n",
    "![residual_block.png](attachment:residual_block.png)\n",
    "\n",
    "Here we let $H(\\textbf{x})$ be the output of a few stacked nonlinear layers where $\\textbf{x}$ is the input to the first of these layers. \n",
    "We'll let these stacked layers fit a residual mapping (the difference between the input and output) with $F(\\textbf{x}) = H(\\textbf{x}) - \\textbf{x}$.\n",
    "Our original function now becomes $H(\\textbf{x}) = F(\\textbf{x}) + \\textbf{x}$. We expect this to be easier for the solvers to optimize as opposed to the original unreferenced mapping.\n",
    "\n",
    "A residual block can be formally defined with the equation\n",
    "$\\textbf{y} = F(\\textbf{x}, \\{W_{i}\\}) + W_s\\textbf{x}$ where $\\textbf{x}, \\textbf{y}$ are the input and output vectors and $F(\\textbf{x}, \\{W_{i}\\})$ is the residual mapping to be learned.\n",
    "For the example block shown here (what we'll be implementing) with two weight layers and a ReLU function, we let $F = W_2 \\sigma (W_1\\textbf{x})$\n",
    "\n",
    "The main thing to takeaway from residual blocks (and what makes ResNets differ from plain CNNs) is the use of the identity shortcut connection which allows the input to be added to the output of the stacked layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd841210",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A single residual block.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1):\n",
    "        super().__init__()\n",
    "        \n",
    "        if(kernel_size % 2 == 0):\n",
    "            raise ValueError(\"Kernel size must be odd!\")\n",
    "            \n",
    "        self._in_channels = in_channels\n",
    "        self._out_channels = out_channels\n",
    "        \n",
    "        self._conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=kernel_size // 2)\n",
    "        self._relu = nn.ReLU()\n",
    "        self._conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, 1, padding=kernel_size // 2)\n",
    "        \n",
    "        if(stride == 1):\n",
    "            self._identity = nn.Identity()\n",
    "        else:\n",
    "            # As paper suggests use convolution with 1x1 kernel and stride of 2 to linearly downsample the data\n",
    "            self._identity = nn.Conv2d(in_channels, out_channels, (1, 1), 2)\n",
    "        \n",
    "        self._relu2 = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        # Non-Linear part...\n",
    "        x_nonlinear = self._conv2(self._relu(self._conv1(x)))\n",
    "        # Linear part...\n",
    "        x_linear = self._identity(x)\n",
    "        return self._relu2(x_nonlinear + x_linear)\n",
    "\n",
    "    \n",
    "class VanillaBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A single vanilla block (no skip connections).\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1):\n",
    "        super().__init__()\n",
    "        \n",
    "        if(kernel_size % 2 == 0):\n",
    "            raise ValueError(\"Kernel size must be odd!\")\n",
    "            \n",
    "        self._in_channels = in_channels\n",
    "        self._out_channels = out_channels\n",
    "        \n",
    "        self._conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=kernel_size // 2)\n",
    "        self._relu = nn.ReLU()\n",
    "        self._conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, 1, padding=kernel_size // 2)\n",
    "        self._relu2 = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        x_nonlinear = self._conv2(self._relu(self._conv1(x)))     \n",
    "        return self._relu2(x_nonlinear)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5476a03c",
   "metadata": {},
   "source": [
    "Now, we'll define a network capable of taking a layer description list and building a ResNet style CNN out of this list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cfba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self,\n",
    "        in_channels: int,\n",
    "        hidden_size: int, \n",
    "        output_size: int,\n",
    "        start_depth: int = 64\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self._output_size = output_size\n",
    "        self._in_channels = in_channels\n",
    "        \n",
    "        l_in = start_depth\n",
    "        \n",
    "        self._initial_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, l_in, 7, stride=1, padding=3),  # Modification, remove stride, makes final image too small...\n",
    "            nn.MaxPool2d(3, 2, padding=1)\n",
    "        )\n",
    "        \n",
    "        # Output dims, kernel size, stride, amount...\n",
    "        layers = self.get_layers(start_depth)\n",
    "        \n",
    "        self._final_layer_len = layers[-1][0]\n",
    "        \n",
    "        residual_layers = []\n",
    "                \n",
    "        for l_out, kernel, stride, count, block_cls in layers:\n",
    "            for i in range(count):\n",
    "                res = block_cls(l_in, l_out, kernel, stride)\n",
    "                residual_layers.append(res)\n",
    "            l_in = l_out\n",
    "        \n",
    "        self._residual_blocks = nn.Sequential(*residual_layers)\n",
    "        \n",
    "        self._final_pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        self._fully_connected = nn.Sequential(\n",
    "            nn.Linear(self._final_layer_len, hidden_size),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "        self._softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x: torch.tensor, run_pooling: bool=True) -> torch.tensor:\n",
    "        batch_size = x.shape[0]\n",
    "        im_shape = x.shape[1:] if(len(x.shape) == 3) else x.shape[2:]\n",
    "        \n",
    "        x = x.reshape(batch_size, self._in_channels, *im_shape)\n",
    "        x = self._initial_conv(x)\n",
    "        x = self._residual_blocks(x)\n",
    "        \n",
    "        if(run_pooling):\n",
    "            x = torch.moveaxis(self._final_pooling(x), 1, -1)\n",
    "            x = x.reshape(-1, self._final_layer_len)\n",
    "            return self._softmax(self._fully_connected(x))\n",
    "        else:\n",
    "            # No pooling: Run the classifier on every pixel in the image...\n",
    "            im_shape = x.shape[2:]\n",
    "            x = torch.moveaxis(x, 1, -1).reshape(-1, self._final_layer_len)\n",
    "            x = self._fully_connected(x)\n",
    "            return x.reshape(batch_size, *im_shape, self._output_size)\n",
    "            \n",
    "    def get_layers(self, start_depth) -> list:\n",
    "        raise NotImplementedError(\"Use one of the ResNet subclasses!\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b707235a",
   "metadata": {},
   "source": [
    "Now we can use this class to define several types of ResNets and regular CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a86f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers: A list of tuples which describe the following in order:\n",
    "# (CNN layer depth, kernel size, stride, number of blocks, block class)\n",
    "        \n",
    "class VanillaNet18(ResNet):\n",
    "    def get_layers(self, l_in: int) -> list:\n",
    "        return [\n",
    "            (l_in, 3, 1, 2, VanillaBlock),\n",
    "            (l_in * 2, 3, 2, 1, VanillaBlock),\n",
    "            (l_in * 2, 3, 1, 1, VanillaBlock),\n",
    "            (l_in * 4, 3, 2, 1, VanillaBlock),\n",
    "            (l_in * 4, 3, 1, 1, VanillaBlock),\n",
    "            (l_in * 8, 3, 2, 1, VanillaBlock),\n",
    "            (l_in * 8, 3, 1, 1, VanillaBlock)\n",
    "        ]\n",
    "    \n",
    "class ResNet18(ResNet):\n",
    "    def get_layers(self, l_in: int) -> list:\n",
    "        return [\n",
    "            (l_in, 3, 1, 2, ResidualBlock),\n",
    "            (l_in * 2, 3, 2, 1, ResidualBlock),\n",
    "            (l_in * 2, 3, 1, 1, ResidualBlock),\n",
    "            (l_in * 4, 3, 2, 1, ResidualBlock),\n",
    "            (l_in * 4, 3, 1, 1, ResidualBlock),\n",
    "            (l_in * 8, 3, 2, 1, ResidualBlock),\n",
    "            (l_in * 8, 3, 1, 1, ResidualBlock)\n",
    "        ]\n",
    "    \n",
    "class VanillaNet34(ResNet):\n",
    "    def get_layers(self, l_in: int) -> list:\n",
    "        return [\n",
    "            (l_in, 3, 1, 3, VanillaBlock),\n",
    "            (l_in * 2, 3, 2, 1, VanillaBlock),\n",
    "            (l_in * 2, 3, 1, 3, VanillaBlock),\n",
    "            (l_in * 4, 3, 2, 1, VanillaBlock),\n",
    "            (l_in * 4, 3, 1, 5, VanillaBlock),\n",
    "            (l_in * 8, 3, 2, 1, VanillaBlock),\n",
    "            (l_in * 8, 3, 1, 2, VanillaBlock)\n",
    "        ]\n",
    "    \n",
    "class ResNet34(ResNet):\n",
    "    def get_layers(self, l_in: int) -> list:\n",
    "        return [\n",
    "            (l_in, 3, 1, 3, ResidualBlock),\n",
    "            (l_in * 2, 3, 2, 1, ResidualBlock),\n",
    "            (l_in * 2, 3, 1, 3, ResidualBlock),\n",
    "            (l_in * 4, 3, 2, 1, ResidualBlock),\n",
    "            (l_in * 4, 3, 1, 5, ResidualBlock),\n",
    "            (l_in * 8, 3, 2, 1, ResidualBlock),\n",
    "            (l_in * 8, 3, 1, 2, ResidualBlock)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453e84e5",
   "metadata": {},
   "source": [
    "We'll define a new ResNet (or non-ResNet) below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac30c8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What values should be here?\n",
    "in_channels = None  # Number of channels in passed data...\n",
    "output_size = None  # Number of output nodes.\n",
    "channel_start = None  # Number of channels to start the residual blocks with.\n",
    "hidden_layer_size = None  # Size of the fully connected hidden layer at the end.\n",
    "model_class = None  # The model class to use.\n",
    "\n",
    "\n",
    "res_net = model_class(in_channels, hidden_layer_size, output_size, channel_start)\n",
    "res_net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56202edc",
   "metadata": {},
   "source": [
    "Now we can train the ResNet using the same methods as the simple model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa5b63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set these! \n",
    "n_epochs2 = None\n",
    "lr2 = None\n",
    "\n",
    "# Set up everything...\n",
    "optimizer2 = optim.SGD(res_net.parameters(), lr=lr2, momentum=0.9)\n",
    "loss_func2 = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7e90c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model...\n",
    "res_net = train_model(res_net, train_loader, test_loader, optimizer2, loss_func2, n_epochs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd416a3a",
   "metadata": {},
   "source": [
    "Let's see how this model performs on augmented data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fee0364",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Normal Test Accuracy: {get_accuracy(res_net, test_loader) * 100:.02f}%\")\n",
    "print(f\"Augmented Test Accuracy: {get_accuracy(res_net, test_loader, img_shift_and_warp) * 100:.02f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c2e40c",
   "metadata": {},
   "source": [
    "The model still performs poorly, but can we achieve better performance by training on the randomly augmented data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8943d90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Retrain using image warping...\n",
    "res_net = train_model(res_net, train_loader, test_loader, optimizer2, loss_func2, n_epochs2, img_shift_and_warp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da1bdf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Normal Test Accuracy: {get_accuracy(res_net, test_loader) * 100:.02f}%\")\n",
    "print(f\"Augmented Test Accuracy: {get_accuracy(res_net, test_loader, img_shift_and_warp) * 100:.02f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1b4e42",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "__What results do you get using the ResNet? How do these differ from the simple fully connected network, and why do you think the results differ?__\n",
    "\n",
    "__Try experimenting with different models above (including non-residual CNNs). How do your results differ from the regular ResNet?__\n",
    "\n",
    "### Bonus Exercise: Localized Results\n",
    "\n",
    "You may wonder if the CNN is not only able to tell us what digit we're looking at, but also where it is located. We can test if the CNN is providing localized results by removing the final average pooling layer, and applying the fully connected layers on every pixel instead of on the average of the pixels. We'll also pass the CNN an image with multiple numbers, to see if it is capable of identifying several numbers across the image.\n",
    "\n",
    "__What results do you observe below? Is the ResNet able to provide localized results?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0177ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img, label in train_loader:\n",
    "    fig = plt.figure(figsize=(6, 20))\n",
    "    axs = fig.subplots(11, 1)\n",
    "    \n",
    "    ax1, axs = axs[0], axs[1:]\n",
    "    \n",
    "    # Take the first set of numbers...\n",
    "    num_nums = min(batch_size, 10)\n",
    "    \n",
    "    img = torch.cat([p for p in img[:num_nums]], dim=1)\n",
    "    \n",
    "    # Network doesn't apply the softmax when we disable pooling, so we apply it here.\n",
    "    # This places all the scores between 0 and 1, and emphasises the highest score. \n",
    "    single_res_grid = torch.softmax(res_net.forward(img.reshape(1, 28, num_nums * 28), False), -1)[0]\n",
    "    \n",
    "    ax1.imshow(img.cpu().detach().numpy(), cmap=\"Greys\")\n",
    "    ax1.set_title(f\"Original Image\\n(Labels: {[int(l) for l in label[:num_nums]]})\")\n",
    "    \n",
    "    for i, ax in enumerate(axs):\n",
    "        ax.set_title(f\"Heatmap of CNN Output: {i}\")\n",
    "        total_len = single_res_grid[:, :, i]\n",
    "        ax.imshow(single_res_grid[:, :, i].cpu().detach().numpy(), vmin=0, vmax=1)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fda7a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
